import tiktoken

class TokenCounter:
    """Tokenç»Ÿè®¡å™¨ï¼Œç”¨äºç»Ÿè®¡å¯¹è¯ä¸­çš„tokenä½¿ç”¨é‡"""
    
    def __init__(self, model_name: str = "qwen3-235b-a22b"):
        # æ ¹æ®æ¨¡å‹é€‰æ‹©åˆé€‚çš„ç¼–ç å™¨
        if "qwen" in model_name.lower():
            self.encoding = tiktoken.get_encoding("o200k_base")  # Qwenä½¿ç”¨o200k_base
        else:
            self.encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
        
        # å½“å‰è½®æ¬¡çš„tokenç»Ÿè®¡
        self.current_round_stats = {
            "user_input_tokens": 0,
            "llm_output_tokens": 0,  # åŒ…æ‹¬æ€ç»´é“¾ã€è‡ªç„¶è¯­è¨€ã€å·¥å…·å‚æ•°
            "tool_result_tokens": 0,
            "total_round_tokens": 0
        }
        
        # æ€»tokenç»Ÿè®¡
        self.total_stats = {
            "total_user_input_tokens": 0,
            "total_llm_output_tokens": 0,
            "total_tool_result_tokens": 0,
            "total_tokens": 0
        }
    
    def count_tokens(self, text: str) -> int:
        """è®¡ç®—æ–‡æœ¬çš„tokenæ•°é‡"""
        if not text:
            return 0
        return len(self.encoding.encode(text))
    
    def count_message_tokens(self, message: dict) -> int:
        """è®¡ç®—æ¶ˆæ¯å¯¹è±¡çš„tokenæ•°é‡"""
        total_tokens = 0
        
        # è®¡ç®—contentçš„token
        if message.get("content"):
            total_tokens += self.count_tokens(str(message["content"]))
        
        # è®¡ç®—thinkingçš„token
        if message.get("thinking"):
            total_tokens += self.count_tokens(str(message["thinking"]))
        
        # è®¡ç®—tool_callsçš„token
        if message.get("tool_calls"):
            for tool_call in message["tool_calls"]:
                if "function" in tool_call:
                    func_name = tool_call["function"].get("name", "")
                    func_args = tool_call["function"].get("arguments", "")
                    total_tokens += self.count_tokens(func_name) + self.count_tokens(func_args)
        
        return total_tokens
    
    def start_new_round(self):
        """å¼€å§‹æ–°ä¸€è½®å¯¹è¯ï¼Œé‡ç½®å½“å‰è½®æ¬¡ç»Ÿè®¡"""
        self.current_round_stats = {
            "user_input_tokens": 0,
            "llm_output_tokens": 0,
            "tool_result_tokens": 0,
            "total_round_tokens": 0
        }
    
    def add_user_input(self, text: str):
        """æ·»åŠ ç”¨æˆ·è¾“å…¥çš„tokenç»Ÿè®¡"""
        tokens = self.count_tokens(text)
        self.current_round_stats["user_input_tokens"] = tokens
        self.total_stats["total_user_input_tokens"] += tokens
    
    def add_llm_output(self, thinking: str = "", content: str = "", tool_calls: list = None):
        """æ·»åŠ LLMè¾“å‡ºçš„tokenç»Ÿè®¡"""
        tokens = 0
        
        # æ€ç»´é“¾token
        if thinking:
            tokens += self.count_tokens(thinking)
        
        # è‡ªç„¶è¯­è¨€å†…å®¹token
        if content:
            tokens += self.count_tokens(content)
        
        # å·¥å…·è°ƒç”¨token
        if tool_calls:
            for tool_call in tool_calls:
                if "function" in tool_call:
                    func_name = tool_call["function"].get("name", "")
                    func_args = tool_call["function"].get("arguments", "")
                    tokens += self.count_tokens(func_name) + self.count_tokens(func_args)
        
        self.current_round_stats["llm_output_tokens"] += tokens
        self.total_stats["total_llm_output_tokens"] += tokens
    
    def add_tool_result(self, result: str):
        """æ·»åŠ å·¥å…·è¿”å›ç»“æœçš„tokenç»Ÿè®¡"""
        tokens = self.count_tokens(str(result))
        self.current_round_stats["tool_result_tokens"] += tokens
        self.total_stats["total_tool_result_tokens"] += tokens
    
    def finish_round(self):
        """å®Œæˆå½“å‰è½®æ¬¡ï¼Œè®¡ç®—æ€»tokenæ•°"""
        self.current_round_stats["total_round_tokens"] = (
            self.current_round_stats["user_input_tokens"] +
            self.current_round_stats["llm_output_tokens"] +
            self.current_round_stats["tool_result_tokens"]
        )
        self.total_stats["total_tokens"] += self.current_round_stats["total_round_tokens"]
    
    def get_round_summary(self) -> str:
        """è·å–å½“å‰è½®æ¬¡çš„tokenç»Ÿè®¡æ‘˜è¦"""
        return f"""
ğŸ“Š å½“å‰è½®æ¬¡Tokenç»Ÿè®¡:
   ğŸ‘¤ ç”¨æˆ·è¾“å…¥: {self.current_round_stats['user_input_tokens']} tokens
   ğŸ¤– LLMè¾“å‡º: {self.current_round_stats['llm_output_tokens']} tokens
   ğŸ”§ å·¥å…·ç»“æœ: {self.current_round_stats['tool_result_tokens']} tokens
   ğŸ“ˆ æœ¬è½®æ€»è®¡: {self.current_round_stats['total_round_tokens']} tokens

ğŸ“Š ç´¯è®¡Tokenç»Ÿè®¡:
   ğŸ‘¤ ç”¨æˆ·è¾“å…¥æ€»è®¡: {self.total_stats['total_user_input_tokens']} tokens
   ğŸ¤– LLMè¾“å‡ºæ€»è®¡: {self.total_stats['total_llm_output_tokens']} tokens
   ğŸ”§ å·¥å…·ç»“æœæ€»è®¡: {self.total_stats['total_tool_result_tokens']} tokens
   ğŸ“Š æ€»è®¡: {self.total_stats['total_tokens']} tokens
"""