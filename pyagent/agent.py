from .frontends import FrontendInterface
from .tools import TOOL_FUNCTIONS, TOOLS
from .token_counter import TokenCounter
from .frontends.image_handler import ImageHandler
from . import conversation_saver
from .context_compressor import ContextCompressor
from .llm_adapter import UnifiedLLMClient
from .conversation_manager import ConversationManager, StreamResponseHandler
import json_repair


class Agent:
    def __init__(
        self, 
        client: UnifiedLLMClient, 
        frontend: FrontendInterface, 
        system_prompt: str, 
        model_name: str,
        model_parameters: list = None
    ):
        self.client = client
        self.frontend = frontend
        self.conversation_manager = ConversationManager(system_prompt)
        self.model_name = model_name
        self.model_parameters = model_parameters or []
        self.token_counter = TokenCounter(model_name)
        self.context_compressor = ContextCompressor(keep_recent_rounds=2)
        
        # è®¾ç½®ç³»ç»Ÿåˆå§‹tokenï¼ˆç³»ç»Ÿæç¤º+å·¥å…·å®šä¹‰ï¼‰
        from .tools import TOOLS
        self.token_counter.set_initial_tokens(system_prompt, TOOLS)
        
        # ä¿å­˜ç³»ç»Ÿæ¶ˆæ¯åˆ°æ•°æ®åº“ï¼ˆç¡®ä¿ç³»ç»Ÿæç¤ºè¢«å­˜å‚¨ï¼‰
        system_message = self.conversation_manager.get_system_message()
        if system_message:
            conversation_saver.save_conversation([system_message])

    def run(self):
        try:
            self.frontend.start_session()
            total_input_tokens = 0
            total_output_tokens = 0
            
            while True:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input, has_input = self.frontend.get_input()
                if not has_input or user_input.lower() == 'é€€å‡º':
                    break
                
                # å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œæå–å›¾åƒ
                clean_text, content_parts = ImageHandler.process_user_input(user_input)
                
                # ç»Ÿè®¡å›¾åƒæ•°é‡
                image_count = len([part for part in content_parts if part.get("type") == "image_url"])
                
                # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°å¯¹è¯ä¸Šä¸‹æ–‡
                self.conversation_manager.add_user_message(clean_text, content_parts)
                conversation_saver.save_conversation([self.conversation_manager.get_last_message()])

                # è®¡ç®—è¾“å…¥tokenæ€»æ•°
                user_tokens = self.token_counter.count_tokens(clean_text)
                image_info = f" å·²æ·»åŠ å›¾åƒ: {image_count}å¼ " if image_count > 0 else ""
                self.frontend.output('info', f"ğŸ“Š ç”¨æˆ·è¾“å…¥: {user_tokens} tokens{image_info}")
                
                # å¤„ç†å¯¹è¯å¾ªç¯ï¼ˆå¯èƒ½åŒ…å«å·¥å…·è°ƒç”¨ï¼‰
                self._process_conversation_round(total_input_tokens, total_output_tokens)

        except Exception as e:
            self.frontend.output('error', f"å‘ç”Ÿé”™è¯¯: {str(e)}")
        finally:
            # ç¨‹åºç»“æŸæ—¶æ¢å¤ç»ˆç«¯é¢œè‰²ä¸ºé»˜è®¤å€¼
            self.frontend.end_session()

    def _process_conversation_round(self, total_input_tokens: int, total_output_tokens: int):
        """å¤„ç†ä¸€è½®å¯¹è¯ï¼ˆå¯èƒ½åŒ…å«å¤šä¸ªå·¥å…·è°ƒç”¨ï¼‰"""
        tool_result_tokens = 0
        
        while True:
            # è·å–å®Œæ•´çš„å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆä¸å†å‹ç¼©ï¼‰
            messages = self.conversation_manager.get_messages_for_sdk()
            
            # è®¡ç®—æœ¬æ¬¡è¯·æ±‚çš„ä¸Šä¸‹æ–‡çª—å£tokené‡
            context_window_tokens = self.token_counter.calculate_conversation_tokens(messages)
            total_input_tokens += context_window_tokens
            
            self._show_context_stats(context_window_tokens, total_input_tokens, total_output_tokens)
            
            # æ„å»ºAPIå‚æ•°
            api_params = self._build_api_params(messages)
            
            # ä½¿ç”¨æ–°çš„äº‹ä»¶æ¥å£å¤„ç†æµå¼å“åº”
            stream = self.client.chat_completions_create_with_events(**api_params)
            
            # åˆ›å»ºæµå¼å“åº”å¤„ç†å™¨
            stream_handler = StreamResponseHandler(self.frontend)
            
            # å¤„ç†æµå¼äº‹ä»¶
            for event in stream:
                stream_handler.handle_stream_event(event)
            
            # è·å–å¤„ç†ç»“æœ
            result = stream_handler.get_result()
            
            # æ›´æ–°è¾“å‡ºtokenç»Ÿè®¡
            thinking_tokens = self.token_counter.count_tokens(result["thinking"]) if result["has_thinking"] else 0
            content_tokens = self.token_counter.count_tokens(result["content"]) if result["has_content"] else 0
            total_output_tokens += thinking_tokens + content_tokens
            
            # æ˜¾ç¤ºtokenç»Ÿè®¡
            self._show_response_stats(thinking_tokens, content_tokens, total_input_tokens, total_output_tokens)
            
            # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å¯¹è¯å†å²
            self.conversation_manager.add_assistant_message(
                result["content"],
                result["thinking"],
                result["tool_calls"]
            )
            conversation_saver.save_conversation([self.conversation_manager.get_last_message()])
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            if result["has_tool_calls"]:
                total_output_tokens += self._execute_tool_calls(result["tool_calls"])
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸå½“å‰è½®æ¬¡
                break

    def _build_api_params(self, messages: list) -> dict:
        """æ„å»ºAPIè°ƒç”¨å‚æ•°"""
        api_params = {
            "model": self.model_name,
            "messages": messages,
            "stream": True,
            "tools": TOOLS,
            "max_tokens": 32000,
        }
        
        # åº”ç”¨æ¨¡å‹å‚æ•°
        for param in self.model_parameters:
            if isinstance(param, list) and len(param) == 2:
                key, value = param
                # å¦‚æœå‚æ•°å€¼ä¸º"Delete"ï¼Œåˆ™ä»api_paramsä¸­ç§»é™¤è¯¥å‚æ•°
                if value == "Delete":
                    if key in api_params:
                        del api_params[key]
                else:
                    api_params[key] = value
        
        return api_params

    def _show_context_stats(self, context_window_tokens: int, total_input_tokens: int, 
                           total_output_tokens: int):
        """æ˜¾ç¤ºä¸Šä¸‹æ–‡ç»Ÿè®¡ä¿¡æ¯"""
        self.frontend.output('info', 
            f"ğŸ“Š ä¸Šä¸‹æ–‡çª—å£: {context_window_tokens/1000} åƒtokens "
            f"ğŸ“Š è¾“å…¥tokenæ€»é‡: {total_input_tokens} tokens  "
            f"ğŸ“Š è¾“å‡ºtokenæ€»é‡: {total_output_tokens} tokens")

    def _show_response_stats(self, thinking_tokens: int, content_tokens: int, 
                           total_input_tokens: int, total_output_tokens: int):
        """æ˜¾ç¤ºå“åº”ç»Ÿè®¡ä¿¡æ¯"""
        self.frontend.output('info', 
            f"ğŸ“Š æ€è€ƒè¾“å‡º: {thinking_tokens} tokens  "
            f"ğŸ“Š å›ç­”è¾“å‡º: {content_tokens} tokens")
        self.frontend.output('info', 
            f"ğŸ“Š è¾“å…¥tokenæ€»é‡: {total_input_tokens} tokens  "
            f"ğŸ“Š è¾“å‡ºtokenæ€»é‡: {total_output_tokens} tokens")

    def _execute_tool_calls(self, tool_calls: list) -> int:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œè¿”å›å·¥å…·è°ƒç”¨çš„tokenæ¶ˆè€—"""
        self.frontend.output('info', "\nå·¥å…·å‚æ•°æ¥æ”¶å®Œæˆï¼Œå¼€å§‹æ‰§è¡Œ...")
        
        tool_calls_tokens = 0
        
        for tool_call in tool_calls:
            function_name = tool_call['function']['name']
            tool_call_id = tool_call['id']
            
            try:
                function_args = json_repair.loads(tool_call['function']['arguments'])
            except Exception as e:
                self.frontend.output("error", 
                    f"å·¥å…·å‚æ•°è§£æå¤±è´¥ï¼š{tool_call['function']['arguments']} - {str(e)}")
                continue
            
            # è®¡ç®—å·¥å…·è°ƒç”¨çš„token
            tool_calls_tokens += (
                self.token_counter.count_tokens(function_name) + 
                self.token_counter.count_tokens(tool_call['function']['arguments'])
            )
            
            if function_name in TOOL_FUNCTIONS:
                try:
                    function_response = TOOL_FUNCTIONS[function_name](**function_args)
                    
                    # æ·»åŠ å·¥å…·è¿”å›ç»“æœåˆ°å¯¹è¯ä¸Šä¸‹æ–‡
                    self.conversation_manager.add_tool_result(tool_call_id, str(function_response))
                    conversation_saver.save_conversation([self.conversation_manager.get_last_message()])
                    
                    # è®¡ç®—å·¥å…·è¿”å›ç»“æœçš„token
                    tool_result_tokens = self.token_counter.count_tokens(str(function_response))
                    self.frontend.output("tool_result", str(function_response))
                    self.frontend.output('info', f"ğŸ“Š å·¥å…·è¿”å›tokené‡: {tool_result_tokens}")
                    
                    # ç´¯åŠ å·¥å…·ç»“æœçš„token
                    tool_calls_tokens += tool_result_tokens
                    
                except Exception as e:
                    self.frontend.output('error', f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥ï¼š{function_name} - {str(e)}")
            else:
                self.frontend.output('error', f"âŒ æœªæ‰¾åˆ°å·¥å…·å‡½æ•°ï¼š{function_name}")
        
        self.frontend.output('info', f"ğŸ“Š è°ƒç”¨è¯·æ±‚è¾“å‡ºtokené‡: {tool_calls_tokens}")
        return tool_calls_tokens